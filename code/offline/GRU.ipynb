{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, GRU, LSTM\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\" # 학습에 사용할 csv 파일이 저장된 폴더입니다.\n",
    "TRAIN_FILE = \"train.csv\" # 학습 및 예측에 사용할 파일입니다.\n",
    "df_data = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_data = df_data.melt(id_vars=['ID', '제품', '대분류', '중분류', '소분류', '브랜드', '쇼핑몰'],\n",
    "                var_name='ds', value_name='y', ignore_index=True)\n",
    "\n",
    "m_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train(df):\n",
    "        data_list = [] \n",
    "        for code in df['ID'].unique():\n",
    "                d = df[df['ID'] == code].reset_index().drop(['index','ID'], axis=1).sort_values('ds')\n",
    "                data_list.append(d)\n",
    "\n",
    "        make = pd.DataFrame(data_list)\n",
    "        return make\n",
    "ds_data = make_train(m_data)\n",
    "ds_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_data.index = ds_data.ds\n",
    "ts_data = ds_data.drop('ds', axis=1)\n",
    "ts_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력값과 출력값 데이터를 위한 코드\n",
    "\n",
    "def ts_train_test_normalize(ts_data, time_steps, for_periods):\n",
    "    \"\"\"\n",
    "    [input]\n",
    "    data : 날짜를 인덱스로 가지는 데이터\n",
    "\n",
    "    [output]\n",
    "    X_train, Y_train : 2022.01.01 ~ 2022.12.31\n",
    "    X_test : 2023.01.01 ~ 2023.04.24\n",
    "    predict : 2023.04.25 ~ 2023.05.15\n",
    "\n",
    "    [time_steps]\n",
    "    input 데이터의 time steps\n",
    "\n",
    "    [for_periods]\n",
    "    output 데이터의 time steps\n",
    "    \"\"\"\n",
    "\n",
    "    # training & test\n",
    "    ts_train = ts_data[:'2022-12-31'].values\n",
    "    ts_test = ts_data['2023-01-01':].values\n",
    "    ts_train_len = len(ts_train)\n",
    "    ts_test_len = len(ts_test)\n",
    "\n",
    "    # scale the data (데이터 정규화)\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    sc = MinMaxScaler(feature_range=(0,1))\n",
    "    ts_train_scaled = sc.fit_transform(ts_train)\n",
    "\n",
    "    # training data sample과 time steps로 원본 데이터 슬라이싱하기\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    y_train_stacked = []\n",
    "\n",
    "    for i in range(time_steps, ts_train_len -1):\n",
    "        X_train.append(ts_train[i-time_steps:i, 0])\n",
    "        y_train.append(ts_train[i:i+for_periods, 0])\n",
    "\n",
    "    X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "    # 3차원으로 재구성하기\n",
    "    # np.reshape(samples, time steps, features) \n",
    "    # 1차원 배열의 shape을 2차원으로 변경하거나, 1차원 배열의 shape을 3차원으로 변경하려고 할때, Numpy 라이브러리에서 제공하는 reshape()함수를 이용\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))\n",
    "\n",
    "    # preparing to create X_test\n",
    "    inputs = pd.concat((ts_data[:'2022-12-31'], ts_data['2023-01-01':]), axis=0).values\n",
    "    inputs = inputs[len(inputs) -len(ts_test) - time_steps:]\n",
    "    inputs = inputs.reshape(-1,1)\n",
    "\n",
    "    X_test = []\n",
    "    for i in range(time_steps, ts_test_len+time_steps-for_periods):\n",
    "        X_test.append(inputs[i-time_steps:i, 0])\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "    return X_train, y_train, X_test, sc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GRU_model(X_train, y_train, X_test, sc):\n",
    "\n",
    "    # GRU 아키텍쳐(architecture)\n",
    "    my_GRU_model = Sequential()\n",
    "    my_GRU_model.add(GRU(units = 50,\n",
    "                           return_sequences = True,\n",
    "                           input_shape = (X_train.shape[1],1),\n",
    "                           activation = 'tanh'))\n",
    "    my_GRU_model.add(GRU(units = 50, activation = 'tanh'))\n",
    "    my_GRU_model.add(Dense(units = 2))\n",
    "\n",
    "    # 컴파일링(compiling)\n",
    "    learning_rate = 0.01\n",
    "    momentum = 0.9\n",
    "    nesterov = False\n",
    "    optimizer = tf.keras.optimizers.legacy.SGD(learning_rate=learning_rate, momentum=momentum, nesterov=nesterov)\n",
    "    my_GRU_model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    # training data 세트에 피팅(fitting)\n",
    "    my_GRU_model.fit(X_train, y_train, epochs = 50, batch_size = 150, verbose = 0)\n",
    "\n",
    "    # X_test를 GRU모델에 넣어서 예측하기\n",
    "    GRU_prediction = my_GRU_model.predict(X_test)\n",
    "\n",
    "    # 스케일러에 예측값 넣어 반환하기\n",
    "    GRU_prediction = sc.inverse_transform(GRU_prediction)\n",
    "\n",
    "    return my_GRU_model, GRU_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_GRU_model, GRU_prediction = GRU_model(X_train, y_train, X_test, sc)\n",
    "GRU_prediction[1:10]\n",
    "actual_pred_plot(GRU_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_gru = pd.DataFrame(GRU_prediction[:, 0])\n",
    "y_test_gru = ts_data['2022-01-01':, 'y'][0:len(GRU_prediction)]\n",
    "y_test_gru.reset_index(drop=True, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
