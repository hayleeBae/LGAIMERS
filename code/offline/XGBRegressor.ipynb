{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import catboost\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"../data\" # 학습에 사용할 csv 파일이 저장된 폴더입니다.\n",
    "TRAIN_FILE = \"train.csv\" # 학습 및 예측에 사용할 파일입니다.\n",
    "TRAIN_PATH = os.path.join(DATA_PATH, TRAIN_FILE)\n",
    "data = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "df_brand = pd.read_csv(os.path.join(DATA_PATH, 'brand_keyword_cnt.csv'))\n",
    "df_info = pd.read_csv(os.path.join(DATA_PATH, 'product_info.csv'))\n",
    "df_sales = pd.read_csv(os.path.join(DATA_PATH, 'sales.csv'))\n",
    "df_smp = pd.read_csv(os.path.join(DATA_PATH, 'sample_submission.csv'))\n",
    "df_data = pd.read_csv(os.path.join(DATA_PATH, 'train.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(TRAIN_PATH)\n",
    "\n",
    "timesize = 60\n",
    "\n",
    "timecol1 = []\n",
    "for times in range(0, timesize):\n",
    "    colname='d'+str(-timesize+times)\n",
    "    timecol1.append(colname)\n",
    "\n",
    "timecol = []\n",
    "for times in range(0, timesize):\n",
    "    colname='d'+str(-timesize+times)\n",
    "    timecol.append(colname)\n",
    "timecol.append(\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28894/28894 [40:31<00:00, 11.88it/s]  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 46\u001b[0m\n\u001b[1;32m     42\u001b[0m         results \u001b[39m=\u001b[39m [\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]\n\u001b[1;32m     44\u001b[0m     FINAL_RESULTS\u001b[39m.\u001b[39mappend(results)\n\u001b[0;32m---> 46\u001b[0m predict_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat(FINAL_RESULTS, ignore_index\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     47\u001b[0m predict_df\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/boost/lib/python3.8/site-packages/pandas/core/reshape/concat.py:372\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39melif\u001b[39;00m copy \u001b[39mand\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    370\u001b[0m     copy \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 372\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    373\u001b[0m     objs,\n\u001b[1;32m    374\u001b[0m     axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m    375\u001b[0m     ignore_index\u001b[39m=\u001b[39;49mignore_index,\n\u001b[1;32m    376\u001b[0m     join\u001b[39m=\u001b[39;49mjoin,\n\u001b[1;32m    377\u001b[0m     keys\u001b[39m=\u001b[39;49mkeys,\n\u001b[1;32m    378\u001b[0m     levels\u001b[39m=\u001b[39;49mlevels,\n\u001b[1;32m    379\u001b[0m     names\u001b[39m=\u001b[39;49mnames,\n\u001b[1;32m    380\u001b[0m     verify_integrity\u001b[39m=\u001b[39;49mverify_integrity,\n\u001b[1;32m    381\u001b[0m     copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m    382\u001b[0m     sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    383\u001b[0m )\n\u001b[1;32m    385\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/boost/lib/python3.8/site-packages/pandas/core/reshape/concat.py:462\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj, (ABCSeries, ABCDataFrame)):\n\u001b[1;32m    458\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    459\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcannot concatenate object of type \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(obj)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m; \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    460\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39monly Series and DataFrame objs are valid\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    461\u001b[0m         )\n\u001b[0;32m--> 462\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg)\n\u001b[1;32m    464\u001b[0m     ndims\u001b[39m.\u001b[39madd(obj\u001b[39m.\u001b[39mndim)\n\u001b[1;32m    466\u001b[0m \u001b[39m# get the sample\u001b[39;00m\n\u001b[1;32m    467\u001b[0m \u001b[39m# want the highest ndim that we have, and must be non-empty\u001b[39;00m\n\u001b[1;32m    468\u001b[0m \u001b[39m# unless all objs are empty\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "DATA_LENGTH, b=data.shape\n",
    "seed = 1994\n",
    "\n",
    "FINAL_RESULTS = []\n",
    "\n",
    "for PRODUCT in tqdm(range(0, DATA_LENGTH)):\n",
    "    FIRST = data.iloc[PRODUCT:PRODUCT+1, 6:6+timesize+1]\n",
    "    FIRST.index = [data.columns[6+timesize]]\n",
    "    FIRST.columns = timecol\n",
    "\n",
    "    for i in range(1, 465-timesize-6):\n",
    "        ADD = data.iloc[PRODUCT:PRODUCT+1, 6+i:6+timesize+i+1]\n",
    "        ADD.index = [data.columns[7+timesize+i]]\n",
    "        ADD.columns = timecol\n",
    "        FIRST = pd.concat([FIRST, ADD])\n",
    "        # FIRST = FIRST.append(ADD, ignore_index=False)\n",
    "\n",
    "    X_train = FIRST.drop(columns=\"target\")\n",
    "    y_train = FIRST['target']\n",
    "\n",
    "    model = XGBRegressor(random_state=seed)\n",
    "    # model = LGBMRegressor(random_state=seed)\n",
    "    # model = CatBoostRegressor(random_state=seed, verbose=0)\n",
    "\n",
    "    try:\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        test_df = data.iloc[PRODUCT:PRODUCT+1, 6+i+1:]\n",
    "        test_df.columns = timecol1\n",
    "\n",
    "        results = []\n",
    "\n",
    "        y_pred = model.predict(test_df)\n",
    "        results.append(round(y_pred[0]))\n",
    "        for PREDICT_TIME in range(0, 20):\n",
    "            test_df = test_df.iloc[:, 1:]\n",
    "            test_df[\"add\"] = round(y_pred[0])\n",
    "            test_df.columns = X_train.columns\n",
    "            y_pred = model.predict(test_df)\n",
    "            results.append(round(y_pred[0]))\n",
    "    except:\n",
    "        results = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
    "\n",
    "    FINAL_RESULTS.append(results)\n",
    "    \n",
    "predict_df = pd.concat(FINAL_RESULTS, ignore_index=True)\n",
    "predict_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat 데이터 csv파일로 저장하기\n",
    "predict_df.to_csv('../submit/submission4.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_FILE = \"sample_submission.csv\"\n",
    "EXAMPLE_PATH = os.path.join(DATA_PATH, EXAMPLE_FILE)\n",
    "\n",
    "submission = pd.read_csv(EXAMPLE_PATH)\n",
    "submit = pd.DataFrame(FINAL_RESULTS)\n",
    "submit[\"ID\"] = submit.index\n",
    "submit = submit[[\"ID\", 0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]]\n",
    "submit.columns = submission.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_PATH = \"../submit\" \n",
    "SUBMISSION_FILE = \"submission4.csv\"\n",
    "SUBMIT_PATH = os.path.join(SAVE_PATH, SUBMISSION_FILE)\n",
    "submit.to_csv(SUBMIT_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
